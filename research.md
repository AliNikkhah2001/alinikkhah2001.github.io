---
layout: page
title: Research
permalink: /research/
---

As a machine learning researcher / engineer, this notebook highlights the programs and questions I am actively exploring. My practice balances rigorous experimentation with deployable systems that partner with clinicians, linguists, and product leaders, keeping science tightly coupled to production.

## Emotion-aware speech translation
- **Lab:** Trinity College Dublin · EmoDub Project
- **Focus:** Preserving affect during multilingual speech-to-speech translation.
- Engineered speech emotion recognition front-ends that blend wav2vec2.0, Whisper, and transformer SER encoders.
- Built multimodal fusion stacks to align acoustic, semantic, and contextual signals for affect-consistent decoding.
- Evaluated BLEU, Emotion F1, and MOS to quantify emotional fidelity alongside translation accuracy.

## Ultrasound report generation
- **Lab:** University of British Columbia
- **Focus:** Automated drafting of ultrasound narratives with trustworthy language models.
- Coupled ViT/BLIP vision encoders with T5 generation heads to produce structured, clinician-ready summaries.
- Curated DICOM-compliant datasets, performed careful de-identification, and integrated saliency overlays for interpretability.
- Collaborated with radiologists to benchmark BLEU, ROUGE-L, and clinical efficacy metrics before deployment.

## Texture-free motion intelligence
- **Lab:** L3S Research Center
- **Focus:** Domain-robust action understanding free from scene texture bias.
- Designed optical-flow-first datasets and augmentations that emphasise temporal cues over backgrounds.
- Trained hybrid 3D CNN and transformer models to generalise across lighting, texture, and capture conditions.
- Analysed attention maps and counterfactuals to explain decisions for reviewers and industry partners.

## Open collaboration
I am highly motivated and actively seeking master's or PhD opportunities that expand this work, and I'm eager to co-author papers or pursue joint experiments around multimodal alignment, affective computing, and applied clinical AI. Each program includes reproducible codebases—agentic evaluation harnesses, data cards, and experiment logs live on GitHub—so collaboration is straightforward. If your lab or company is building in these areas, please [reach out](/contact/) or email [alinkkh9@gmail.com](mailto:alinkkh9@gmail.com).
